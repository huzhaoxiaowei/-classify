# âœ… ä¸»ç¨‹åºï¼šå•é˜¶æ®µè®­ç»ƒ + å¯é€‰ GAF åˆ†ç±»ä¸»å¹²ç»“æ„ï¼ˆEffNetV2 / ConvNeXt / ResNeSt ç­‰ï¼‰
import numpy as np
import sys
import os
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from sklearn.model_selection import StratifiedGroupKFold
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
import re
from collections import defaultdict

# ã€ä¿®æ”¹ç‚¹1ã€‘å°†æ‰€æœ‰æ¨¡å‹å¯¼å…¥é›†ä¸­ç®¡ç†
# 1. ä» TensorFlow Keras å¯¼å…¥æ ‡å‡†æ¨¡å‹
from tensorflow.keras.applications import (
    MobileNetV2,
    EfficientNetV2S,
    EfficientNetV2M,
    ResNet50
)

# 2. å°è¯•ä» keras-cv-attention-models å¯¼å…¥æ‰©å±•æ¨¡å‹
#    å¦‚æœéœ€è¦ä½¿ç”¨ ConvNeXt, ResNeSt, SEResNeXt ç­‰æ¨¡å‹ï¼Œè¯·å…ˆå®‰è£…åº“: pip install keras-cv-attention-models
try:
    from keras_cv_attention_models import resnest, seresnext, convnext

    HAS_EXTRA_MODELS = True
    print("âœ… å·²æˆåŠŸåŠ è½½ keras_cv_attention_models æ‰©å±•æ¨¡å‹åº“ã€‚")
except ImportError:
    HAS_EXTRA_MODELS = False
    print("âš ï¸ æç¤ºï¼šæ— æ³•å¯¼å…¥ keras_cv_attention_modelsã€‚ConvNeXt, ResNeSt, SEResNeXt ç­‰æ¨¡å‹å°†ä¸å¯ç”¨ã€‚")
    # å®šä¹‰å ä½ç¬¦ï¼Œä»¥é˜²ä»£ç å› æœªå®šä¹‰è€ŒæŠ¥é”™
    resnest, seresnext, convnext = None, None, None

# 3. å¯¼å…¥æˆ‘ä»¬é‡æ„å¥½çš„ç”Ÿæˆå™¨
try:
    from generator1_4 import AdvancedDataGenerator
except ImportError:
    print("âŒ è‡´å‘½é”™è¯¯ï¼šæ— æ³•ä» generator1_4.py å¯¼å…¥ AdvancedDataGeneratorã€‚è¯·ç¡®ä¿æ–‡ä»¶åå’Œè·¯å¾„æ­£ç¡®ã€‚")
    sys.exit()

# ------------------ ğŸ§ª å‚æ•°é…ç½®åŒº (åªæ”¹è¿™é‡Œ) ------------------
# --- å®éªŒè®¾ç½® ---
PHASE_TO_TRAIN = "å‘å‰ç›´è¡Œé˜¶æ®µ"  # å¯é€‰: "èµ·ç«‹é˜¶æ®µ", "æ‹å¼¯é˜¶æ®µ", "å‘å‰ç›´è¡Œé˜¶æ®µ", "å‘åç›´è¡Œé˜¶æ®µ", "åä¸‹é˜¶æ®µ"
DATA_DIR = r'/root/autodl-tmp/project/å®éªŒæ•°æ®/å‡è®¾æ•°æ®/å¤„ç†åçš„æ•°æ®'

# --- æ¨¡å‹é€‰æ‹© ---
# æ”¯æŒçš„æ¨¡å‹: 'efficientnetv2-s', 'efficientnetv2-m', 'mobilenetv2', 'resnet50'
# å¦‚æœå®‰è£…äº†æ‰©å±•åº“ï¼Œè¿˜æ”¯æŒ: 'convnext-tiny', 'convnext-small', 'resnest50', 'seresnext50'
BACKBONE_NAME = 'efficientnetv2-s'

# --- æ•°æ®å¤„ç†å‚æ•° ---
WINDOW_SIZE = 256  # æˆªå–çš„æ—¶é—´çª—å£å¤§å° (åŸå§‹è®ºæ–‡ä¸º896)
STEP = 64  # æ»‘åŠ¨çª—å£çš„æ­¥é•¿
FEATURE_INDEX = 0  # ä½¿ç”¨ç¬¬å‡ ä¸ªç‰¹å¾æ¥ç”Ÿæˆå›¾åƒ (0ä»£è¡¨ç¬¬ä¸€ä¸ª)

# --- è®­ç»ƒå‚æ•° ---
TARGET_IMAGE_SIZE = 224  # æ¨¡å‹æœ€ç»ˆè¾“å…¥çš„å›¾åƒå°ºå¯¸
BATCH_SIZE = 16
EPOCHS = 50
LEARNING_RATE = 1e-4


# ------------------ æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (ä¿æŒä¸å˜) ------------------
def generate_patient_id_map(base_dir):
    # ...å†…å®¹ä¸å˜...
    patient_id_map = {}
    pattern = re.compile(r'(\d+[ZP])_(imu_data|pressure_data)\.npy')
    for fname in os.listdir(base_dir):
        match = pattern.match(fname)
        if match:
            pid = match.group(1)
            if match.group(2) == 'imu_data':
                patient_id_map[pid] = 0 if 'Z' in pid else 1
    return patient_id_map


def load_data(data_dir, pid_map):
    # ...å†…å®¹ä¸å˜...
    imu_list, p_list, label_list, pid_list = [], [], [], []
    for pid, label in pid_map.items():
        imu_path = os.path.join(data_dir, f"{pid}_imu_data.npy")
        p_path = os.path.join(data_dir, f"{pid}_pressure_data.npy")
        if os.path.exists(imu_path) and os.path.exists(p_path):
            imu = np.load(imu_path)
            pres = np.load(p_path)
            min_len = min(len(imu), len(pres))
            imu_list.append(imu[:min_len])
            p_list.append(pres[:min_len])
            label_list.extend([label] * min_len)
            pid_list.extend([pid] * min_len)
    return np.concatenate(imu_list), np.concatenate(p_list), np.array(label_list), np.array(pid_list)


def split_by_phase_five(pids, stand_ratio=0.1, walk_straight_ratio=0.3, turn_ratio=0.2, walk_back_ratio=0.3):
    # ...å†…å®¹ä¸å˜...
    grouped = defaultdict(list)
    for i, pid in enumerate(pids):
        grouped[pid].append(i)

    stand, forward, turn, back, sit = [], [], [], [], []
    for pid, idxs in grouped.items():
        n = len(idxs)
        s_end = int(n * stand_ratio)
        f_end = s_end + int(n * walk_straight_ratio)
        t_end = f_end + int(n * turn_ratio)
        b_end = t_end + int(n * walk_back_ratio)
        stand.extend(idxs[:s_end])
        forward.extend(idxs[s_end:f_end])
        turn.extend(idxs[f_end:t_end])
        back.extend(idxs[t_end:b_end])
        sit.extend(idxs[b_end:])
    return {"èµ·ç«‹é˜¶æ®µ": stand, "å‘å‰ç›´è¡Œé˜¶æ®µ": forward, "æ‹å¼¯é˜¶æ®µ": turn, "å‘åç›´è¡Œé˜¶æ®µ": back, "åä¸‹é˜¶æ®µ": sit}

# ------------------ ã€ä¿®æ”¹ç‚¹2ã€‘å®Œå–„çš„æ¨¡å‹å·¥å‚ ------------------
def build_backbone(model_name, input_shape):
    name = model_name.lower()
    # ä» tf.keras.applications åŠ è½½
    if name == 'efficientnetv2-s':
        return EfficientNetV2S(input_shape=input_shape, include_top=False, weights='imagenet')
    elif name == 'efficientnetv2-m':
        return EfficientNetV2M(input_shape=input_shape, include_top=False, weights='imagenet')
    elif name == 'mobilenetv2':
        return MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')
    elif name == 'resnet50':
        return ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')
    # ä» keras_cv_attention_models åŠ è½½
    elif HAS_EXTRA_MODELS:
        if name == 'convnext-tiny':
            return convnext.ConvNeXtTiny(input_shape=input_shape, include_top=False, pretrained=True)
        elif name == 'convnext-small':
            return convnext.ConvNeXtSmall(input_shape=input_shape, include_top=False, pretrained=True)
        elif name == 'seresnext50':
            return seresnext.SEResNeXt50(input_shape=input_shape, include_top=False, pretrained=True)
        elif name == 'resnest50':
            return resnest.ResNeSt50(input_shape=input_shape, include_top=False, pretrained=True)
    # å¦‚æœæ‰¾ä¸åˆ°æ¨¡å‹æˆ–æœªå®‰è£…ä¾èµ–ï¼Œåˆ™æŠ¥é”™
    raise ValueError(f"æ¨¡å‹ '{model_name}' æ— æ•ˆæˆ–å…¶ä¾èµ–åº“æœªå®‰è£…ã€‚è¯·æ£€æŸ¥ BACKBONE_NAME å‚æ•°ã€‚")


def build_model(input_shape, num_classes=2, model_name='efficientnetv2-s'):
    base = build_backbone(model_name, input_shape)
    base.trainable = False
    x = GlobalAveragePooling2D()(base.output)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)
    out = Dense(num_classes, activation='softmax')(x)
    return Model(inputs=base.input, outputs=out)


# ------------------ å•é˜¶æ®µè®­ç»ƒï¼ˆå·²æ›´æ–°ï¼‰ ------------------
def train_single_phase(X_raw, y_raw, pid_raw, idx, phase_name):
    X_sel, y_sel, pid_sel = X_raw[idx], y_raw[idx], pid_raw[idx]
    skf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)
    aucs, accs = [], []

    for fold, (train_i, val_i) in enumerate(skf.split(X_sel, y_sel, groups=pid_sel)):
        print(f"\nğŸ“¦ ç¬¬ {fold + 1}/5 æŠ˜ - {phase_name}")

        train_gen = AdvancedDataGenerator(
            raw_data=X_sel[train_i], raw_labels=y_sel[train_i], raw_patient_ids=pid_sel[train_i],
            window_size=WINDOW_SIZE, step=STEP, target_image_size=TARGET_IMAGE_SIZE,
            feature_index=FEATURE_INDEX, batch_size=BATCH_SIZE, shuffle=True, is_rgb=True
        )
        val_gen = AdvancedDataGenerator(
            raw_data=X_sel[val_i], raw_labels=y_sel[val_i], raw_patient_ids=pid_sel[val_i],
            window_size=WINDOW_SIZE, step=STEP, target_image_size=TARGET_IMAGE_SIZE,
            feature_index=FEATURE_INDEX, batch_size=BATCH_SIZE, shuffle=False, is_rgb=True
        )

        if len(train_gen) == 0 or len(val_gen) == 0:
            print("âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ‰¹æ¬¡ï¼Œè·³è¿‡æ­¤æŠ˜ã€‚")
            continue

        # ã€ä¿®æ”¹ç‚¹3ã€‘ä¿®å¤BUGï¼šç¡®ä¿æ¨¡å‹å’Œç”Ÿæˆå™¨çš„å›¾åƒå°ºå¯¸ä¸€è‡´
        model_input_shape = (TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE, 3)
        model = build_model(input_shape=model_input_shape, num_classes=2, model_name=BACKBONE_NAME)
        model.compile(optimizer=Adam(LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy'])

        model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS,
                  callbacks=[ReduceLROnPlateau(patience=5, factor=0.5),
                             EarlyStopping(patience=10, restore_best_weights=True)],
                  verbose=1)

        # è¯„ä¼°é€»è¾‘...
        y_true, y_score = [], []
        for i in range(len(val_gen)):
            Xb, yb = val_gen[i]
            preds = model.predict(Xb, verbose=0)
            y_score.extend(preds[:, 1])
            y_true.extend(np.argmax(yb, axis=1))

        if len(np.unique(y_true)) > 1:
            auc = roc_auc_score(y_true, y_score)
            _, acc = model.evaluate(val_gen, verbose=0)
            aucs.append(auc)
            accs.append(acc)
            print(f"âœ… Fold AUC = {auc:.4f}, Accuracy = {acc:.4f}")
        else:
            print("âš ï¸ éªŒè¯é›†æ ‡ç­¾å•ä¸€ï¼Œæ— æ³•è®¡ç®—AUCã€‚")

    if aucs:
        print(f"\nğŸ“Š ã€{phase_name}ã€‘å¹³å‡ AUC = {np.mean(aucs):.4f}")
        print(f"ğŸ“Š ã€{phase_name}ã€‘å¹³å‡ Acc = {np.mean(accs):.4f} Â± {np.std(accs):.4f}")
    else:
        print(f"âš ï¸ ã€{phase_name}ã€‘æ— æœ‰æ•ˆç»“æœã€‚")


# ------------------ ä¸»è¿è¡Œå…¥å£ ------------------
if __name__ == "__main__":
    print(f"ğŸ§ª å³å°†è®­ç»ƒé˜¶æ®µ: {PHASE_TO_TRAIN}ï¼Œä½¿ç”¨æ¨¡å‹: {BACKBONE_NAME}")
    pid_map = generate_patient_id_map(DATA_DIR)
    X_imu, X_pressure, y_labels, pid_array = load_data(DATA_DIR, pid_map)

    X_imu_std = StandardScaler().fit_transform(X_imu.reshape(-1, X_imu.shape[-1])).reshape(X_imu.shape)
    X_pressure_std = StandardScaler().fit_transform(X_pressure)
    X_combined = np.concatenate([X_imu_std.reshape(X_imu_std.shape[0], -1), X_pressure_std], axis=1)

    phase_indices_dict = split_by_phase_five(pid_array)
    selected_indices = np.array(phase_indices_dict[PHASE_TO_TRAIN])

    train_single_phase(X_combined, y_labels, pid_array, selected_indices, PHASE_TO_TRAIN)